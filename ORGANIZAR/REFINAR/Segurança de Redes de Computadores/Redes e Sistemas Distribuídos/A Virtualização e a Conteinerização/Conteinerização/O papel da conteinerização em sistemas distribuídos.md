[![](https://ampli-images.s3.amazonaws.com/production/0e34d0e9-d09b-4bcb-915f-7431c8dd6458/original)](https://ampli-images.s3.amazonaws.com/production/0e34d0e9-d09b-4bcb-915f-7431c8dd6458/original)

Os sistemas distribuÃ­dos fazem uso extensivo dos contÃªineres no contexto de microsserviÃ§os. A ideia dos microsserviÃ§os estÃ¡ associada a empresas que possuem sistemas altamente dinÃ¢micos e ao termo modularidade. Um portal de notÃ­cias por exemplo, Ã© composto por vÃ¡rios elementos, como um (ou mais) banco de dados, um (ou mais)Â _framework front-end_Â utilizado para desenvolver interfaces,Â _framework back-end_Â para desenvolver a parte dinÃ¢mica do sistema, frameworks para gerenciar mensagens entre servidores e clientes (por exemplo, o RabbitMQ) etc.

Caso o sistema possua uma arquitetura monolÃ­tica, ou seja, uma forte dependÃªncia entre esses elementos, serÃ¡ muito difÃ­cil substituir alguns dos elementos citados anteriormente sem causar uma interrupÃ§Ã£o completa no sistema. Por outro lado, em uma arquitetura baseada em microsserviÃ§os, esses componentes tÃªm um baixo acoplamento entre si, ou seja, o grau de dependÃªncia entre os componentes Ã© baixo, de forma que, caso vocÃª tenha de fazer uma substituiÃ§Ã£o, terÃ¡ um impacto bem menor na indisponibilidade do seu sistema, e os contÃªineres serÃ£o artefatos fundamentais para atingir esse baixo acoplamento, pois cada um dos elementos pode ser criado e implantado em um contÃªiner separado.

Dentre as vantagens de um sistema distribuÃ­do baseado em microsserviÃ§os, podemos apontar que quanto menores sÃ£o as partes, mais fÃ¡cil entendÃª-las. AlÃ©m disso, cada microsserviÃ§o pode ser executado e escalado de maneira concorrente e independente entre si. Outra vantagem decorrente disso Ã© que, como esses elementos possuem um baixo acoplamento entre si, um projeto de grande porte pode ser trabalhado de maneira razoavelmente independente entre as equipes de trabalho. A figura a seguir ilustra uma aplicaÃ§Ã£o monolÃ­tica em relaÃ§Ã£o a uma aplicaÃ§Ã£o baseada em microsserviÃ§os.

[![](https://ampli-images.s3.amazonaws.com/production/81ad8564-85e8-41cc-882e-e2acc9c01eee/original)](https://ampli-images.s3.amazonaws.com/production/81ad8564-85e8-41cc-882e-e2acc9c01eee/original)

Exemplo de aplicaÃ§Ãµes baseadas em microsserviÃ§os. Fonte: elaborada pelo autor.

______

**ğŸ”Assimile**

Atualmente, existe uma grande tendÃªncia de empresas migrarem de aplicaÃ§Ãµes monolÃ­ticas para aplicaÃ§Ãµes orientadas a microsserviÃ§os, por vantagens como escalabilidade e independÃªncia entre seus elementos (tambÃ©m conhecido como baixo acoplamento).

______

Como veremos na prÃ³xima aula (parte prÃ¡tica), apesar de a criaÃ§Ã£o e o controle de um contÃªiner ser feita com simples comandos, podemos observar pela figura acima que uma aplicaÃ§Ã£o Ã© composta por nÃ£o apenas um, mas vÃ¡rios microsserviÃ§os, cada um representando um ou mais contÃªineres. Gerenciar dezenas ou centenas de contÃªiner, de maneira isolada, pode ser uma tarefa muito trabalhosa, razÃ£o pela qual as empresas utilizam alguma ferramenta para criar, gerenciar e remover contÃªineres.

Esse tipo de ferramenta Ã© conhecido no mercado de trabalho como ferramenta de orquestraÃ§Ã£o de contÃªineres. Acredita-se que a ideia esteja relacionada ao fato de que, em uma orquestra, um maestro coordena os mÃºsicos de maneira que o objetivo conjunto (obra tocada) seja o melhor possÃ­vel. Nessa analogia, as ferramentas de orquestraÃ§Ã£o realizam o mesmo papel do maestro, em que os mÃºsicos seriam os contÃªineres.

Atualmente, a ferramenta de orquestraÃ§Ã£o mais popular e, portanto, mais solicitada no mercado de trabalho Ã© o Kubernetes, da Google, que serve para orquestrar contÃªineres criados com o Docker. Importante notar que o prÃ³prioÂ _framework_Â do Docker possui uma ferramenta de orquestraÃ§Ã£o nativa, instalada automaticamente com o Docker. Essa ferramenta Ã© chamada deÂ _**Swarm**_. Em alguns aspectos, inclusive pelo fato de ser uma ferramenta totalmente integrada com o Docker, oÂ _Swarm_Â Ã© a mais indicada para um primeiro contato com o conceito de orquestraÃ§Ã£o de contÃªineres.

OÂ _Swarm_Â foi integrado ao Docker a partir da versÃ£o 1.12.0, com o chamado swarm mode, em junho de 2016, conforme noticiado no blog oficial do Docker (DOCKER, [s.d.]) A figura abaixo ajudarÃ¡ a entender os componentes doÂ _Swarm_Â e como eles estÃ£o relacionados aos contÃªineres.

[![](https://ampli-images.s3.amazonaws.com/production/89c32eb2-8154-425c-a7be-310ab1862b8c/original)](https://ampli-images.s3.amazonaws.com/production/89c32eb2-8154-425c-a7be-310ab1862b8c/original)

Arquitetura do Swarm do Docker. Fonte: elaborada pelo autor.

Na figura acima, o retÃ¢ngulo destacado em lilÃ¡s representa o que o Docker chama de Swarm, que nada mais Ã© que um cluster (conjunto de computadores interligados que funcionam como um grande sistema), formado por vÃ¡rios nÃ³s, que podem rodar uma aplicaÃ§Ã£o â€“ no exemplo, o servidor webÂ _**Nginx**_Â â€“ de maneira integrada e distribuÃ­da. Para que os nÃ³s possam estar integrados, de maneira que, caso uma instÃ¢ncia doÂ _Nginx_Â falhe por conta de um dos nÃ³s escravos estar indisponÃ­vel, esta ser automaticamente instanciada em outro nÃ³, Ã© necessÃ¡rio que exista um nÃ³ mestre que faÃ§a essa gestÃ£o.

Podem existir vÃ¡rios nÃ³s com a funÃ§Ã£o de mestre do cluster (que o Docker chama de manager), para que, caso o nÃ³ mestre falhe, outro nÃ³ mestre assuma seu lugar. Os nÃ³s escravos (que o Docker chama deÂ _worker_) rodam a quantidade de instÃ¢ncias (frequentemente chamadas de rÃ©plicas) solicitadas pelo nÃ³ mestre e, para tal, Ã© preciso que exista um contÃªiner â€œdentroâ€ de cada nÃ³ escravo, o que estÃ¡ representado pelo retÃ¢ngulo laranja.