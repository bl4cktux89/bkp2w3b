# **IntroduÃ§Ã£o da aula**

[![](https://ampli-images.s3.amazonaws.com/production/cc2f236d-5b67-4717-b1bf-5127b8c09679/original)](https://ampli-images.s3.amazonaws.com/production/cc2f236d-5b67-4717-b1bf-5127b8c09679/original)

### **Qual Ã© o foco da aula?**

Nesta aula,Â vocÃª terÃ¡ contato com a base teÃ³rica sobre modalidades de teste e sobre registros de atividades no processo.

### **Objetivos gerais de aprendizagem**

Ao longo desta aula, vocÃª irÃ¡:

- identificar o funcionamento dos testes de unidade e integraÃ§Ã£o;
- examinar os testes de usuÃ¡rio;
- interpretar como sÃ£o elaborados os relatÃ³rios de qualidade doÂ _software_.

**SituaÃ§Ã£o-problema**

Nesta etapa do nosso estudo, jÃ¡ concordamos que os testes sÃ£o fundamentais no processo de desenvolvimento de um produto. Sem que as devidas verificaÃ§Ãµes sejam feitas, nÃ£o hÃ¡ a mÃ­nima seguranÃ§a de que o sistema se comportarÃ¡ conforme o esperado.

A expressÃ£o â€œdevidas verificaÃ§Ãµesâ€ demanda atenÃ§Ã£o especial de nossa parte: ela indica, entre outras coisas, a necessidade de aplicaÃ§Ã£o do teste certo, pela pessoa certa e no tempo devido.

Antes de iniciarmos a abordagem teÃ³rica, Ã© bom que nos lembremos que temos adquirido, ao longo do curso, conhecimento das principais metodologias de desenvolvimento deÂ _software_, das normas de qualidade e, nesta unidade, dos processos de teste deÂ _software_. Temos como objetivo especÃ­fico, nesta aula, conhecer o que sÃ£o e como implementar o teste de release e o teste de usuÃ¡rio.

Conforme constataremos na sequÃªncia, nÃ£o hÃ¡ apenas um tipo de teste a ser feito no produto. As verificaÃ§Ãµes devem focar desde o desempenho do programa atÃ© sua adequaÃ§Ã£o Ã  mÃ¡quina em que serÃ¡ executado. NÃ£o se pode conceber tambÃ©m que apenas uma pessoa ou grupo realize os testes. Diferentes pontos de vista e interesses devem ser acomodados pelo processo, fato que tambÃ©m deu motivo para a criaÃ§Ã£o de vÃ¡rias modalidades de teste.

Ainda resta uma questÃ£o a ser abordada: Ã© vÃ¡lido e Ãºtil o registro dos resultados obtidos no teste? Podemos considerar esses registros base para criaÃ§Ã£o de histÃ³rico do processo? Desta maneira, serÃ¡ nesta aula que abordaremos esses assuntos que circunstanciam o processo de teste e que serÃ£o argumento para o desafio desta aula.

Novamente se faz necessÃ¡rio resgatarmos o desafio que dÃ¡ sentido ao nosso curso: fazer com que aÂ _XAX-Sooft_Â atinja bom nÃ­vel de excelÃªncia em seus processos e produtos, tendo como ponto de partida uma organizaÃ§Ã£o sem processo definido e sem qualquer padronizaÃ§Ã£o de qualidade. Em especÃ­fico, nossa missÃ£o nesta aula Ã© fazer o registro dos resultados obtidos com a aplicaÃ§Ã£o do teste deÂ _software_Â como meio eficiente de formar uma base para manutenÃ§Ã£o do histÃ³rico dos processos.

Bons estudos!

# **Testes de unidade e de integraÃ§Ã£o**

[![](https://ampli-images.s3.amazonaws.com/production/1d886edd-f1cf-42ab-b190-286d1e08c781/original)](https://ampli-images.s3.amazonaws.com/production/1d886edd-f1cf-42ab-b190-286d1e08c781/original)

Para entender um teste de unidade, imagine oÂ _software_Â como um conjunto de partes que, juntas, formam o todo. Essa modalidade de teste Ã© direcionada a uma rotina, classe ou pequena parte de um produto e Ã© normalmente executada pelo prÃ³prio desenvolvedor, de modo a assegurar que determinada unidade poderÃ¡ ser integrada ao resto doÂ _software_.

No contexto dos testes de unidade (ou testes unitÃ¡rios) insere-se um elemento conhecido como stub. Ele simula resultados que sÃ£o retornados por um determinado componente do qual oÂ _software_Â depende (PINHEIRO, 2015). Em outras palavras, um stub Ã© um trecho de cÃ³digo que substituirÃ¡ as entradas, dependÃªncias e comunicaÃ§Ãµes que a unidade deveria receber em uma execuÃ§Ã£o do programa. Quando um componente A que vai ser testado chama operaÃ§Ãµes de outro componente B que ainda nÃ£o foi implementado, pode-se criar uma implementaÃ§Ã£o simplificada de B, chamada stub. Neste caso, devemos entender que o componente A Ã© a unidade a ser testada.

_____

**ğŸ“ Exemplificando**

Veja um bom exemplo de aplicaÃ§Ã£o de um stub: Suponha que o componente A Ã© uma classe que deve usar um gerador de nÃºmeros primos B. A implementaÃ§Ã£o de B ainda nÃ£o foi feita. No entanto, para testar a unidade A nÃ£o serÃ¡ necessÃ¡ria a geraÃ§Ã£o de alguns poucos nÃºmeros primos. Assim, B pode ser substituÃ­do por uma funÃ§Ã£o stub que gera apenas os 5 primeiros nÃºmeros primos (WAZLAWICK, 2013).

_____

HÃ¡ situaÃ§Ãµes, no entanto, em que o mÃ³dulo B jÃ¡ estÃ¡ implementado, mas o mÃ³dulo A (que aqui representa nossa unidade) que chama as funÃ§Ãµes de B ainda nÃ£o foi implementado. DeverÃ¡ ser implementada, entÃ£o, uma simulaÃ§Ã£o do mÃ³dulo A, que recebe o nome de driver. A diferenÃ§a entre stubs e drivers concentra-se na relaÃ§Ã£o de dependÃªncia entre os componentes. As tÃ©cnicas de teste funcional e estrutural, ambas abordadas anteriormente nesta unidade, podem ser utilizadas para a execuÃ§Ã£o de um teste de unidade.

O teste funcional serve para validar a funÃ§Ã£o especÃ­fica que estÃ¡ sob teste. Quando utilizada, a tÃ©cnica de teste estrutural (ou caixa-branca) viabiliza a validaÃ§Ã£o dos fluxos de execuÃ§Ã£o da unidade. Ambas as tÃ©cnicas podem ser utilizadas de forma combinada ou isolada num teste de unidade.

_____

**ğŸ’­ Reflita**

Os stubs, como sabemos, geram valores de entrada para unidades que serÃ£o testadas. VocÃª entende como legÃ­timo que um stub seja construÃ­do tambÃ©m para gerar valores errados para a classe, por exemplo?

_____

**Testes de integraÃ§Ã£o**

Trata-se de teste executado pelo testador para garantir que vÃ¡rios componentes do sistema funcionem corretamente juntos (PINHEIRO, 2015). Eles sÃ£o feitos quando as unidades (as classes, por exemplo) jÃ¡ foram testadas de forma isolada e precisam ser integradas para gerar uma nova versÃ£o doÂ _software_.

No caso de as classes a serem testadas precisarem de comunicaÃ§Ã£o com outros componentes ou classes que ainda nÃ£o foram testadas â€“ ou mesmo implementadas â€“, os stubs mais uma vez serÃ£o necessÃ¡rios. O problema com um stub Ã© que se investe tempo para desenvolver uma funÃ§Ã£o que nÃ£o serÃ¡ efetivamente entregue. AlÃ©m disso, nem sempre Ã© possÃ­vel saber se a simulaÃ§Ã£o produzida pelo stub serÃ¡ suficientemente adequada para os testes (WAZLAWICK, 2013).

Com o sistema integrado e testado, chega o momento de entregÃ¡-lo ao usuÃ¡rio para que ele o teste tambÃ©m.

# **Teste de usuÃ¡rio (ou teste de aceitaÃ§Ã£o)**

[![](https://ampli-images.s3.amazonaws.com/production/a358e96b-c2e9-4cde-b567-c110e5b01545/original)](https://ampli-images.s3.amazonaws.com/production/a358e96b-c2e9-4cde-b567-c110e5b01545/original)

Quando jÃ¡ se dispÃµe da interface final do sistema, o teste de aceitaÃ§Ã£o jÃ¡ pode ser aplicado. Como o prÃ³prio nome nos faz supor, esse teste Ã© executado pelo usuÃ¡rio e nÃ£o pela equipe de testadores ou desenvolvedores. Para entendermos melhor essa modalidade de teste, Ã© interessante que a coloquemos em oposiÃ§Ã£o ao teste de sistema.

OÂ **teste de sistema**Â Ã© feito quando todas as unidades e as integraÃ§Ãµes entre elas jÃ¡ foram testadas. Pode ser que a equipe jÃ¡ se sinta confiante o bastante nesse ponto para assumir que seu produto Ã© de boa qualidade. No entanto, Ã© necessÃ¡rio que ele passe por esse novo teste depois de integrado. O objetivo da sua aplicaÃ§Ã£o Ã© o de verificar se o programa Ã© capaz de executar processos completos, sempre adotando o ponto de vista do usuÃ¡rio.

Pois bem, o teste de usuÃ¡rio pode ser planejado tal qual o teste de sistema. A diferenÃ§a Ã© que ele serÃ¡ executado pelo usuÃ¡rio. Em outras palavras, enquanto o teste de sistema faz aÂ _verificaÃ§Ã£o_Â do sistema, o teste de aceitaÃ§Ã£o faz suaÂ _validaÃ§Ã£o_.

_____

**ğŸ“ Exemplificando**

Um plano viÃ¡vel para a realizaÃ§Ã£o de teste de aceitaÃ§Ã£o em um programa de vendas pela internet Ã© o que segue no quadro abaixo:

[![](https://ampli-images.s3.amazonaws.com/production/093065d1-cb3a-48ec-b58e-c9c2f146eff2/original)](https://ampli-images.s3.amazonaws.com/production/093065d1-cb3a-48ec-b58e-c9c2f146eff2/original)

Exemplo de roteiro para teste de aceitaÃ§Ã£o. Fonte: adaptado de Wazlawick (2013, p. 296).

_____

O teste de aceitaÃ§Ã£o Ã© chamado deÂ **Teste Alfa**Â quando feito pelo cliente sem planejamento rÃ­gido ou formalidades. Se o teste Ã© ainda menos controlado pelo time de desenvolvimento e as versÃµes do programa sÃ£o testadas por vÃ¡rios usuÃ¡rios, sem acompanhamento direto ou controle da desenvolvedora, entÃ£o o procedimento Ã© chamado deÂ **Teste Beta**. Nesta modalidade, as versÃµes disponibilizadas costumam expirar depois de certo tempo de uso.

______

**ğŸ” Assimile**

O teste de aceitaÃ§Ã£o visa Ã  validaÃ§Ã£o dos requisitos implementados noÂ _software_, nÃ£o mais a verificaÃ§Ã£o de defeitos (WAZLAWICK, 2013).

______

Um termo bastante comum no contexto dos testes de aceitaÃ§Ã£o Ã© oÂ _release_. Literalmente, o termo refere-se a uma liberaÃ§Ã£o ou lanÃ§amento de uma nova versÃ£o de um produto deÂ _software_. Os testes aplicados sobre um release seguem o padrÃ£o dos testes de usuÃ¡rio. Usualmente, um lanÃ§amento obedece Ã s seguintes fases:

- alfa: nesta fase, o lanÃ§amento ainda estÃ¡ em processo de testes, que sÃ£o realizados por pessoas situadas normalmente fora do processo de desenvolvimento. Os produtos em fase de teste alfa podem ser instÃ¡veis e sujeitos a travamento.
- beta: trata-se da classificaÃ§Ã£o posterior a Alfa. Um lanÃ§amento em beta teste Ã© avaliado por testadores beta, normalmente clientes em potencial que aceitam a tarefa de teste sem cobrar por isso. Uma versÃ£o Beta Ã© utilizada para demonstraÃ§Ãµes dentro da organizaÃ§Ã£o e para clientes externos.
- _Release Candidate_: trata-se de versÃ£o do sistema com potencial para ser a versÃ£o final. Neste caso, todas as funcionalidades jÃ¡ foram devidamente testadas por meio das fases Alfa e Beta.

UmÂ _release_Â pode ser interno ou externo. O primeiro Ã© usado somente pela equipe interna de desenvolvimento para fins de controle ou para demonstraÃ§Ã£o a clientes e usuÃ¡rios. Um release externo Ã© uma versÃ£o do produto distribuÃ­da para os usuÃ¡rios finais (BARTIÃ‰, 2002).

De uma forma ou de outra, as modalidades de teste apresentadas atÃ© aqui relacionam-se diretamente Ã s funcionalidades do sistema. Em outras palavras, elas fazem a verificaÃ§Ã£o dos processos que efetivamente devem ser realizados pelo programa. No entanto, a abrangÃªncia dos testes Ã© maior e demanda a aplicaÃ§Ã£o de outros tipos de verificaÃ§Ãµes no produto. A esses tipos damos o nome de testes suplementares. Vejamos dois exemplos a seguir.

a)Â **Teste de Desempenho**: tipo que tem por objetivo determinar se, nas situaÃ§Ãµes de pico mÃ¡ximo de acesso e concorrÃªncia, o desempenho ainda permanece consistente com o que foi definido para essa caracterÃ­stica do sistema. Assim, o critÃ©rio de sucesso aqui Ã© a obtenÃ§Ã£o de tempo de resposta compatÃ­vel com o que se espera do produto, quando o sistema trabalha em seu limite. Um plano possÃ­vel para esse teste estÃ¡ descrito a seguir (BARTIÃ‰, 2002):

- validar todos os requisitos de desempenho identificados;
- simular n usuÃ¡rios acessando a mesma informaÃ§Ã£o, de forma simultÃ¢nea;
- simular n usuÃ¡rios processando a mesma transaÃ§Ã£o, de forma simultÃ¢nea;
- simular n% de trÃ¡fego na rede;
- combinar todos esses elementos.

Quando o procedimento eleva ao mÃ¡ximo a quantidade de dados e transaÃ§Ãµes Ã s quais o sistema Ã© submetido, o teste realizado Ã© chamado deÂ **Teste de Estresse**. Ele Ã© realizado para que se possa verificar se o sistema Ã© suficientemente robusto em situaÃ§Ãµes extremas de carga de trabalho.

b)Â **Teste de recuperaÃ§Ã£o**: seu objetivo Ã© avaliar oÂ _software_Â apÃ³s a ocorrÃªncia de uma falha ou de uma situaÃ§Ã£o anormal de funcionamento. Algumas aplicaÃ§Ãµes demandam alta disponibilidade do programa e, no caso de falha, oÂ _software_Â deve ter a capacidade de se manter em execuÃ§Ã£o atÃ© que a condiÃ§Ã£o adversa desapareÃ§a.

Os testes de recuperaÃ§Ã£o devem prever tambÃ©m os procedimentos de recuperaÃ§Ã£o do estado inicial da transaÃ§Ã£o interrompida, impedindo que determinados processamentos sejam realizados pela metade (BARTIÃ‰, 2002).

Normalmente, o teste de recuperaÃ§Ã£o trata de situaÃ§Ãµes referentes a (WAZLAWICK, 2013):

- queda de energia na organizaÃ§Ã£o em que o sistema estÃ¡ em funcionamento;
- discos corrompidos;
- problemas de queda de comunicaÃ§Ã£o;
- quaisquer outras condiÃ§Ãµes que possam provocar a terminaÃ§Ã£o anormal do programa ou a interrupÃ§Ã£o temporÃ¡ria em seu funcionamento.

_____

**â• Pesquise mais**

Ã‰ possÃ­vel que, ao se aplicar uma manutenÃ§Ã£o num programa, outros defeitos sejam gerados no cÃ³digo? Acertou se respondeu que sim. Leia o artigo â€œ[_A importÃ¢ncia dos testes de regressÃ£o_](http://gtsw.blogspot.com/2009/03/importancia-dos-testes-de-regressao.html)â€.

_____

Pois bem, eis entÃ£o algumas das outras modalidades de teste e outros conceitos relacionados Ã  atividade. Chega a hora, entÃ£o, de tratarmos dos registros das atividades de teste, visando capacitÃ¡-lo ainda mais para o desafio desta aula. Vamos a eles?

# **Os relatÃ³rios da qualidade do software**

[![](https://ampli-images.s3.amazonaws.com/production/8ac004b7-fc36-4ba4-96a6-6508a2cc32bb/original)](https://ampli-images.s3.amazonaws.com/production/8ac004b7-fc36-4ba4-96a6-6508a2cc32bb/original)

O registro das atividades relacionadas ao processo de qualidade, sobretudo os testes, sÃ£o feitos em relatÃ³rios especÃ­ficos. AlÃ©m do efetivo registro, eles servem tambÃ©m como instrumentos de mediÃ§Ã£o e anÃ¡lise. A execuÃ§Ã£o do teste deve gerar o que chamamos de log, que nada mais Ã© do que o registro das atividades desempenhadas. Vamos a alguns deles:

- log de execuÃ§Ã£o: este documento Ã© criado para registrar todos os procedimentos realizados durante a execuÃ§Ã£o de um ciclo de testes, bem como apontar as eventuais interrupÃ§Ãµes ocorridas. O log de execuÃ§Ã£o certifica que, de fato, o teste foi realizado.
- ocorrÃªncias da validaÃ§Ã£o: neste documento registram-se todas as ocorrÃªncias geradas durante um teste. Uma ocorrÃªncia pode ser, por exemplo, a identificaÃ§Ã£o de um defeito. Neste caso, alguns dos dados a serem relatados serÃ£o: um nome ou nÃºmero de identificaÃ§Ã£o do defeito, a data em que foi encontrado e a sequÃªncia de aÃ§Ãµes capazes de reproduzi-lo (BARTIÃ‰, 2002).

Um dado tambÃ©m bastante importante a ser registrado Ã© a classificaÃ§Ã£o do defeito. Apesar de haver muitas classificaÃ§Ãµes, alguns deles sÃ£o mais relevantes:

a)Â **falha na descriÃ§Ã£o funcional**: esta classificaÃ§Ã£o refere-se Ã  discrepÃ¢ncia entre a descriÃ§Ã£o da funcionalidade e sua efetiva implementaÃ§Ã£o. Por exemplo: a descriÃ§Ã£o da funcionalidade estabelece que o programa deveria promover acrÃ©scimo trimestral automÃ¡tico do salÃ¡rio dos gerentes de seÃ§Ã£o e o sistema aplica o aumento a cada quatro meses;

b)Â **falha no controle, lÃ³gica ou sequenciamento do algoritmo**: um laÃ§o de repetiÃ§Ã£o infinito Ã© um exemplo desse tipo de falha;

c)Â **falha nas estruturas de dados:**Â trata-se da definiÃ§Ã£o incorreta, por exemplo, de matrizes e tabelas de banco de dados;

O relatÃ³rio de teste, em resumo, serve para registrar a maior quantidade possÃ­vel de dados acerca do processo.

_____

**ğŸ’ª FaÃ§a vocÃª mesmo**

A norma IEEE 829 Ã© o padrÃ£o criado pela IEEE para documentaÃ§Ã£o do processo de teste. Um dos relatÃ³rios recomendados pelo padrÃ£o Ã© o de incidente de teste, que prevÃª a descriÃ§Ã£o dos seguintes itens, entre outros, em caso de ocorrÃªncia de um incidente: entradas, resultados esperados e resultados encontrados. Vale registrar que um incidente pode ser entendido como discrepÃ¢ncia entre o resultado esperado e o encontrado na execuÃ§Ã£o dos casos de teste.

Crie um exemplo de um processo de teste que contemple uma entrada de caso de teste, faÃ§a previsÃ£o de um resultado esperado para aquela entrada e forneÃ§a a descriÃ§Ã£o do resultado obtido.

# **ConclusÃ£o**

[![](https://ampli-images.s3.amazonaws.com/production/3ab1ae4e-ad0a-404f-b930-4492530cb9f6/original)](https://ampli-images.s3.amazonaws.com/production/3ab1ae4e-ad0a-404f-b930-4492530cb9f6/original)

A caminhada daÂ _XAX-Sooft_Â rumo Ã  excelÃªncia nÃ£o para! Depois de fazer a seleÃ§Ã£o dos casos de teste e de efetivamente aplicar teste funcional em um dos seus produtos, aÂ _XAX-Sooft_Â vÃª-se na necessidade de fazer um registro criterioso das atividades desempenhadas no processo de teste, com a finalidade de criar base de comparaÃ§Ã£o para testes futuros. Afinal, como saber se a aplicaÃ§Ã£o de um mÃ©todo foi bem-sucedida se nÃ£o pela comparaÃ§Ã£o entre dois ou mais resultados?

Vale a pena dizer que, na prÃ¡tica, os registros dos resultados obtidos no teste sÃ£o feitos no ato da sua aplicaÃ§Ã£o ou em situaÃ§Ã£o inserida em seu contexto. Por exemplo, as anotaÃ§Ãµes referentes Ã  ocorrÃªncia de uma falha no algoritmo devem ser feitas assim que ela acontece, no momento do teste. Para efeito de organizaÃ§Ã£o didÃ¡tica, esta aula coloca o registro das ocorrÃªncias e resultados como etapa posterior Ã  aplicaÃ§Ã£o do teste, embora nÃ£o o seja de fato.

Pois bem, o desafio lanÃ§ado aqui Ã© justamente o de registrar o processo e os resultados obtidos com a aplicaÃ§Ã£o do teste deÂ _software_Â em um dos seus produtos. O que deve ser registrado? O que nÃ£o deve ser registrado? HÃ¡ formato definido? Uma soluÃ§Ã£o possÃ­vel para esse desafio Ã© a seguinte:

- A equipe deve criar, oficializar e publicar um log de execuÃ§Ãµes, ou seja, um formulÃ¡rio apropriado para que todos os registros de ocorrÃªncias sejam feitos;
- O formulÃ¡rio de registro deve conter, no mÃ­nimo, os seguintes campos:

1. responsÃ¡veis pelo teste;data e horÃ¡rio de inÃ­cio;data e horÃ¡rio de tÃ©rmino;Â funÃ§Ã£o, unidade ou sistema testados;Â fase do teste: teste de unidade, teste de integraÃ§Ã£o ou teste de sistema;Â falha na interpretaÃ§Ã£o da funÃ§Ã£o: nesta seÃ§Ã£o devem ser relatadas as divergÃªncias entre a funÃ§Ã£o especificada nos requisitos e a funÃ§Ã£o de fato implementada;Â falha na construÃ§Ã£o de estrutura de dados: erros na criaÃ§Ã£o de tabelas e outras estruturas devem ser registrados aqui;Â defeito algorÃ­tmico: devem ser identificados erros de lÃ³gicas, laÃ§os infinitos, por exemplo;travamento de origem nÃ£o identificada;Â outras ocorrÃªncias relevantes.

Esse formulÃ¡rio pode â€“ e deve â€“ passar por constante aprimoramento em seus campos e em sua utilizaÃ§Ã£o.

_____

**âš ï¸ AtenÃ§Ã£o**

O formato doÂ _log_Â de execuÃ§Ãµes Ã© livre e deve ser definido pela equipe, segundo critÃ©rios prÃ³prios.

______

**ğŸ“ŒLembre-se**

A norma IEEE 829 Ã© o padrÃ£o criado pela IEEE para documentaÃ§Ã£o do processo de teste.